/* tslint:disable */
/* eslint-disable */
/**
 * Pinecone Assistant Data Plane API
 * Pinecone Assistant Engine is a context engine to store and retrieve relevant knowledge from millions of documents at scale. This API supports interactions with assistants.
 *
 * The version of the OpenAPI document: 2025-04
 * Contact: support@pinecone.io
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { exists, mapValues } from '../runtime';
import type { ContextOptionsModel } from './ContextOptionsModel';
import {
    ContextOptionsModelFromJSON,
    ContextOptionsModelFromJSONTyped,
    ContextOptionsModelToJSON,
} from './ContextOptionsModel';
import type { MessageModel } from './MessageModel';
import {
    MessageModelFromJSON,
    MessageModelFromJSONTyped,
    MessageModelToJSON,
} from './MessageModel';

/**
 * The list of queries / chats to chat an assistant
 * @export
 * @interface Chat
 */
export interface Chat {
    /**
     * 
     * @type {Array<MessageModel>}
     * @memberof Chat
     */
    messages: Array<MessageModel>;
    /**
     * If false, the assistant will return a single JSON response. If true, the assistant will return a stream of responses.
     * @type {boolean}
     * @memberof Chat
     */
    stream?: boolean;
    /**
     * The large language model to use for answer generation
     * @type {string}
     * @memberof Chat
     */
    model?: ChatModelEnum;
    /**
     * Controls the randomness of the model's output: lower values make responses more deterministic, while higher values increase creativity and variability. If the model does not support a temperature parameter, the parameter will be ignored.
     * @type {number}
     * @memberof Chat
     */
    temperature?: number;
    /**
     * Optionally filter which documents can be retrieved using the following metadata fields.
     * @type {object}
     * @memberof Chat
     */
    filter?: object;
    /**
     * If true, the assistant will be instructed to return a JSON response. Cannot be used with streaming.
     * @type {boolean}
     * @memberof Chat
     */
    jsonResponse?: boolean;
    /**
     * If true, the assistant will be instructed to return highlights from the referenced documents that support its response.
     * @type {boolean}
     * @memberof Chat
     */
    includeHighlights?: boolean;
    /**
     * 
     * @type {ContextOptionsModel}
     * @memberof Chat
     */
    contextOptions?: ContextOptionsModel;
}


/**
 * @export
 */
export const ChatModelEnum = {
    Gpt4o: 'gpt-4o',
    Gpt41: 'gpt-4.1',
    O4Mini: 'o4-mini',
    Claude35Sonnet: 'claude-3-5-sonnet',
    Claude37Sonnet: 'claude-3-7-sonnet',
    Gemini25Pro: 'gemini-2.5-pro'
} as const;
export type ChatModelEnum = typeof ChatModelEnum[keyof typeof ChatModelEnum];


/**
 * Check if a given object implements the Chat interface.
 */
export function instanceOfChat(value: object): boolean {
    let isInstance = true;
    isInstance = isInstance && "messages" in value;

    return isInstance;
}

export function ChatFromJSON(json: any): Chat {
    return ChatFromJSONTyped(json, false);
}

export function ChatFromJSONTyped(json: any, ignoreDiscriminator: boolean): Chat {
    if ((json === undefined) || (json === null)) {
        return json;
    }
    return {
        
        'messages': ((json['messages'] as Array<any>).map(MessageModelFromJSON)),
        'stream': !exists(json, 'stream') ? undefined : json['stream'],
        'model': !exists(json, 'model') ? undefined : json['model'],
        'temperature': !exists(json, 'temperature') ? undefined : json['temperature'],
        'filter': !exists(json, 'filter') ? undefined : json['filter'],
        'jsonResponse': !exists(json, 'json_response') ? undefined : json['json_response'],
        'includeHighlights': !exists(json, 'include_highlights') ? undefined : json['include_highlights'],
        'contextOptions': !exists(json, 'context_options') ? undefined : ContextOptionsModelFromJSON(json['context_options']),
    };
}

export function ChatToJSON(value?: Chat | null): any {
    if (value === undefined) {
        return undefined;
    }
    if (value === null) {
        return null;
    }
    return {
        
        'messages': ((value.messages as Array<any>).map(MessageModelToJSON)),
        'stream': value.stream,
        'model': value.model,
        'temperature': value.temperature,
        'filter': value.filter,
        'json_response': value.jsonResponse,
        'include_highlights': value.includeHighlights,
        'context_options': ContextOptionsModelToJSON(value.contextOptions),
    };
}

